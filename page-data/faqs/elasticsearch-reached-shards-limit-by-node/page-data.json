{"componentChunkName":"component---src-pages-faqs-markdown-remark-frontmatter-slug-js","path":"/faqs/elasticsearch-reached-shards-limit-by-node/","result":{"data":{"markdownRemark":{"html":"<h3>Issue</h3>\n<p>Error in Elasticsearch/Wazuh indexer:</p>\n<pre><code>\"Validation Failed: 1: this action would add [2] total shards, but this cluster currently has [999]/[1000] maximum shards open;\"\n</code></pre>\n<h3>Remediation</h3>\n<p>This means the shards limit count was reached (<code>1000</code> by default in the node). To fix this issue, there are multiple options:</p>\n<ul>\n<li><strong>Delete indices</strong>. This frees shards. You could do it with old indices you don't want/need. Or even, you could automate it with ILM/ISM policies to delete old indices after a period of time as explained in this post: <a href=\"https://wazuh.com/blog/wazuh-index-management\">https://wazuh.com/blog/wazuh-index-management</a>.</li>\n</ul>\n<p>Note:</p>\n<ul>\n<li>ILM: Index Lifecycle Management (used by X-Pack)</li>\n<li>ISM: Index State Management (used by Open Distro for Elasticsearch and OpenSearch)</li>\n</ul>\n<p>The automation of the indices deletion through ILM/ISM policies is recommended because reduces manual maintenance.</p>\n<ul>\n<li>\n<p><strong>Add more nodes</strong> to your Elasticserach/Wazuh indexer cluster.</p>\n</li>\n<li>\n<p><strong>Increment the max shards per node</strong> (not recommended). But if you do this option, make sure you do not increase it too much, as it could cause inoperability and performance issues in your Elasticsearch/Wazuh indexer cluster. To do this:</p>\n<pre><code class=\"language-sh\">curl -k -u USERNAME:PASSWORD -XPUT ELASTICSEARCH_HOST_ADDRESS/_cluster/settings -H \"Content-Type: application/json\" \\\n-d '{ \"persistent\": { \"cluster.max_shards_per_node\": \"MAX_SHARDS_PER_NODE\" } }'\n</code></pre>\n<p>replace the placeholders, where:</p>\n<ul>\n<li><code>USERNAME</code> : username to do the request</li>\n<li><code>PASSWORD</code> : password for the user</li>\n<li><code>ELASTICSEARCH_HOST_ADDRESS</code>: Elasticsearch/Wazuh indexer host address. Include the protocol https if needed.</li>\n<li><code>MAX_SHARDS_PER_NODE</code>: Maximum shards by node. Maybe you could try with 1200 o something like that, depending of your case.</li>\n</ul>\n</li>\n<li>\n<p><strong>Reduce the shards consumed by the indices</strong>: reduce the shards of existent indices and configure if possible for the new ones.</p>\n<ul>\n<li><code>wazuh-alerts-4.x-*</code> indices: <a href=\"https://documentation.wazuh.com/current/user-manual/elasticsearch/elastic-tuning.html#shards-and-replicas\">https://documentation.wazuh.com/current/user-manual/elasticsearch/elastic-tuning.html#shards-and-replicas</a>.</li>\n<li><code>wazuh-monitoring-*</code> and <code>wazuh-statistics-*</code> indices: they can be configured in the Wazuh plugin settings from the UI <code>Settings/Configuration</code> or through the configuration file <code>wazuh.yml</code>.</li>\n<li>General application <a href=\"https://opster.com/guides/elasticsearch/capacity-planning/elasticsearch-reduce-shards/\">https://opster.com/guides/elasticsearch/capacity-planning/elasticsearch-reduce-shards/</a>.</li>\n</ul>\n</li>\n</ul>\n<p>More info: <a href=\"https://www.elastic.co/blog/how-many-shards-should-i-have-in-my-elasticsearch-cluster\">https://www.elastic.co/blog/how-many-shards-should-i-have-in-my-elasticsearch-cluster</a>.</p>","frontmatter":{"date":"September 15, 2020","slug":"elasticsearch-reached-shards-limit-by-node","title":"Reached the shards limit by node","tags":["elasticsearch","shards","wazuh-indexer"],"version":"","description":"shards limits","author":""}}},"pageContext":{"id":"7f171211-da4b-5ee3-8d70-1e60239e0729","frontmatter__slug":"elasticsearch-reached-shards-limit-by-node","__params":{"frontmatter__slug":"elasticsearch-reached-shards-limit-by-node"}}},"staticQueryHashes":["1340339594"]}